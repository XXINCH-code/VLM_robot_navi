{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff3f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n",
      "simple_corridor\n"
     ]
    }
   ],
   "source": [
    "from crowd_nav.configs.config import Config\n",
    "import numpy as np\n",
    "\n",
    "for i in range(10):\n",
    "    #np.random.seed()\n",
    "    config = Config()\n",
    "    print(config.env.csl_workspace_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a0d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5, carrying, simple_corridor; 3, static, simple_corridor; 4, static, simple_corridor\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"openai.env\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "image_paths = [\"test2.png\"]\n",
    "\n",
    "# 将图片编码为 base64，用于上传\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def encode_image_from_bytes(image_bytes):\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "# 构建图像消息 payload\n",
    "image_payloads = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/png;base64,{encode_image(path)}\",\n",
    "        }\n",
    "    }\n",
    "    for path in image_paths\n",
    "]\n",
    "'''\n",
    "image_payloads = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/png;base64,{encode_image_from_bytes(image_bytes)}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "'''\n",
    "\n",
    "# 提示词\n",
    "prompt_text = \"Suppose you are a wheeled robot performing social navigation tasks in a simulation environment. All green cylinders in the picture are humans. Please judge the current human activity and the robot's current environment based on the image I uploaded. Please select one output from ['walking', 'carrying', 'static', 'talking'] and ['simple_corner', 'simple_corridor'] respectively. Requirement: Only output the judgment content, do not output redundant content, and do not explain why. Output format: human_id, human activity, env, give all the info of detected human in this format\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [*image_payloads, {\"type\": \"text\", \"text\": prompt_text}]}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # 也可尝试 \"gpt-4-turbo\"\n",
    "    messages=messages,\n",
    "    max_tokens=100,\n",
    "    temperature=0.0,  # 保持回答一致性\n",
    ")\n",
    "\n",
    "# 打印回答\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '4']\n",
      "['simple_corridor', 'simple_corridor', 'simple_corridor']\n",
      "['carrying', 'static', 'static']\n"
     ]
    }
   ],
   "source": [
    "# 分割\n",
    "entries = [entry.strip() for entry in response.choices[0].message.content.split(\";\") if entry.strip()]\n",
    "\n",
    "human_id_list = []\n",
    "activities = []\n",
    "scene_type_list = []\n",
    "\n",
    "for entry in entries:\n",
    "    parts = entry.split(\", \")\n",
    "    if len(parts) == 3:\n",
    "        human_id_list.append(parts[0])\n",
    "        activities.append(parts[1])\n",
    "        scene_type_list.append(parts[2])\n",
    "print(human_id_list)\n",
    "print(scene_type_list)\n",
    "print(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca58350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navirobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
